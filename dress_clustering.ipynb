{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9712a0",
   "metadata": {},
   "source": [
    "# Dress images clustering\n",
    "\n",
    "The goal of this notebook is to combine dresses in pictures into big groups by their style with a help from crowd.\n",
    "\n",
    "We are going to use a sample from [FEIDEGGER dataset (Lefakis, Akbik, and Vollgraf 2018)](https://github.com/zalandoresearch/feidegger)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831195ad",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Toloka/crowdclustering/blob/main/dress_clustering.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053647b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip3 -q install toloka-kit==0.1.26\n",
    "!pip3 -q install pandas\n",
    "!pip3 -q install ipyplot\n",
    "!pip3 -q install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113d0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sys import stdout\n",
    "from time import sleep\n",
    "from typing import Dict, List, Optional, Set\n",
    "from random import sample, shuffle\n",
    "from getpass import getpass\n",
    "from math import log\n",
    "\n",
    "import ipyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import toloka.client as toloka\n",
    "\n",
    "from exam_check import exam_check\n",
    "from calculate_quality import calculate_quality\n",
    "from crowd_clustering_aggregation import clustering_aggregation, Prior, AggregationAssignment\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import TextArea, DrawingArea, OffsetImage, AnnotationBbox\n",
    "import matplotlib.image as mpimg\n",
    "sns.set_theme()\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='[%(levelname)s] %(name)s: %(message)s',\n",
    "    level=logging.INFO,\n",
    "    stream=stdout,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa5132",
   "metadata": {},
   "source": [
    "Сreate toloka-client instance. All api calls will go through it. More about OAuth token in Toloka-Kit [Learn the basics example](https://github.com/Toloka/toloka-kit/tree/main/examples/0.getting_started/0.learn_the_basics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627d0b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your token:········\n",
      "[INFO] root: Requester(_unexpected={}, id='b39ea2ce2474c437ed0ee0d4aeec630b', balance=Decimal('1010.6390'), public_name={'EN': 'Ya.Apollyon', 'FR': 'Ya.Apollyon', 'ID': 'Ya.Apollyon', 'RU': 'Я.Аполлион', 'TR': 'Ya.Apollyon'}, company=Requester.Company(_unexpected={}, id='1', superintendent_id='56caaaeeea84b3b3765420ef45a08262'))\n"
     ]
    }
   ],
   "source": [
    "toloka_client = toloka.TolokaClient(getpass('Enter your token:'), 'PRODUCTION')\n",
    "logging.info(toloka_client.get_requester())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb2aa4b",
   "metadata": {},
   "source": [
    "## Creating Training and Exam project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b8a07e",
   "metadata": {},
   "source": [
    "As our task is rather uncommon for crowdsourcing platforms we need our workers to train before proceeding to main pools. So, this is how it is going to work:\n",
    "\n",
    "* We create a Training and Exam project with training pool for workers to train and main pool to check workers' performance;\n",
    "* After training workers are going to pass an main pool at least 3 times as an exam;\n",
    "* After first exam worker is to be assigned a Dress Clustering Skill, the skill value is calculated as percentage of correctly chosen clusters divided by number of exams expected (3 in our case);\n",
    "* Only those workers who have been assigned the Shoes Clustering Skill with 100% skill value are allowed to perform on the main project\n",
    "\n",
    "Let's start with creating Training and Exam project from a json file with the help of auxilliary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61f1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_project_from_file(project_config_path: str, create: bool = True) -> toloka.Project:\n",
    "    with open(project_config_path) as project_config_file:\n",
    "        json_string = project_config_file.read()\n",
    "    project = toloka.Project.from_json(json_string)\n",
    "    if create:\n",
    "        return toloka_client.create_project(project)\n",
    "    else:\n",
    "        return project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c457bce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'crowdclustering'...\n",
      "remote: Enumerating objects: 112, done.\u001b[K\n",
      "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
      "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
      "remote: Total 112 (delta 48), reused 76 (delta 27), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (112/112), 110.22 KiB | 1.21 MiB/s, done.\n",
      "Resolving deltas: 100% (48/48), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Toloka/crowdclustering.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba61bf4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/likhobaba-dp/Documents/GitHub/crowdclustering/crowdclustering\n"
     ]
    }
   ],
   "source": [
    "cd crowdclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15130b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] toloka.client: A new project with ID \"138318\" has been created. Link to open in web interface: https://toloka.yandex.com/requester/project/138318\n"
     ]
    }
   ],
   "source": [
    "training_exam_project = create_project_from_file('configs/dress/training_exam/project.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405f7c1",
   "metadata": {},
   "source": [
    "Then we create training and add traininig tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ba7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_from_file(training_config_path: str, project_id: str, create: bool = True) -> toloka.Training:\n",
    "    with open(training_config_path) as training_config_file:\n",
    "        json_string = training_config_file.read()\n",
    "    training = toloka.Training.from_json(json_string)\n",
    "    training.project_id = project_id\n",
    "    if create:\n",
    "        return toloka_client.create_training(training)\n",
    "    else:\n",
    "        return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0853e834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] toloka.client: A new training with ID \"38456272\" has been created. Link to open in web interface: https://toloka.yandex.com/requester/project/138318/training/38456272\n"
     ]
    }
   ],
   "source": [
    "training = create_training_from_file('configs/dress/training_exam/training.json', training_exam_project.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4029efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tasks_from_config(training_tasks_config_path: str, training_id: str, \n",
    "                             create: bool = True) -> List[toloka.Task]:\n",
    "    tasks = []\n",
    "    \n",
    "    with open(training_tasks_config_path) as training_tasks_config_file:\n",
    "        tasks_configs = json.load(training_tasks_config_file)\n",
    "    \n",
    "    for training_task in tasks_configs:\n",
    "        task = toloka.Task.structure(training_task)\n",
    "        task.pool_id = training_id\n",
    "        tasks.append(task)\n",
    "    \n",
    "    if create:\n",
    "        return toloka_client.create_tasks(tasks)\n",
    "    else:\n",
    "        return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd08700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = create_tasks_from_config('configs/dress/training_exam/training_tasks.json', training.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa36f1f",
   "metadata": {},
   "source": [
    "And finally create pool with tasks to be an exam for workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f43827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pool_from_file(pool_config_path: str, project_id: str, \n",
    "                          training_id: Optional[str] = None, create: bool = True) -> toloka.Pool:\n",
    "    with open(pool_config_path) as pool_config_file:\n",
    "        json_string = pool_config_file.read()\n",
    "    pool = toloka.Pool.from_json(json_string)\n",
    "    pool.project_id = project_id\n",
    "    if training_id is not None:\n",
    "        pool.quality_control.training_requirement.training_pool_id = training_id\n",
    "    pool.will_expire = datetime.now() + timedelta(days=7)\n",
    "    if create:\n",
    "        return toloka_client.create_pool(pool)\n",
    "    else:\n",
    "        return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7f19eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] toloka.client: A new pool with ID \"38456274\" has been created. Link to open in web interface: https://toloka.yandex.com/requester/project/138318/pool/38456274\n"
     ]
    }
   ],
   "source": [
    "exam_pool = create_pool_from_file('configs/dress/training_exam/exam_pool.json', training_exam_project.id, training.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "647edcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_suites_from_directory(task_suites_path: str, pool_id: str) -> List[toloka.TaskSuite]:\n",
    "    task_suites = []\n",
    "    \n",
    "    for task_suite_file_name in os.listdir(task_suites_path):\n",
    "        task_suite_file_path = os.path.join(task_suites_path, task_suite_file_name)\n",
    "        if os.path.isfile(task_suite_file_path) and task_suite_file_path.endswith('.json'):\n",
    "            with open(task_suite_file_path) as task_config_file:\n",
    "                json_string = task_config_file.read()\n",
    "            \n",
    "            task_suite = toloka.Task.from_json(json_string)\n",
    "            task_suite.pool_id = pool_id\n",
    "            \n",
    "            task_suites.append(task_suite)\n",
    "    \n",
    "    return toloka_client.create_task_suites(task_suites, allow_defaults=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bf006e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_suites = create_task_suites_from_directory('configs/dress/training_exam/exam_tasks/', exam_pool.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e62e1",
   "metadata": {},
   "source": [
    "Last thing we do on this Training and Exam project preparation is skill creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2400af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] toloka.client: A new skill with ID \"64216\" has been created. Link to open in web interface: https://toloka.yandex.com/requester/quality/skill/64216\n"
     ]
    }
   ],
   "source": [
    "skill = toloka_client.create_skill(name='Dress clustering')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de7322",
   "metadata": {},
   "source": [
    "Our Training and Exam project is ready! But we won't open training and exam pools yet as we have payed exam. It is recommended to open payed exams exactly when they are needed and close when they aren't needed anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0fe3e8",
   "metadata": {},
   "source": [
    "## Creating a main project\n",
    "\n",
    "Let's proceed on creating a main project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70dc1576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] toloka.client: A new project with ID \"138319\" has been created. Link to open in web interface: https://toloka.yandex.com/requester/project/138319\n"
     ]
    }
   ],
   "source": [
    "main_project = create_project_from_file('configs/dress/project/project.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e13f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pool = create_pool_from_file('configs/dress/project/pool.json', main_project.id, create=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f649d",
   "metadata": {},
   "source": [
    "There is one thing we have to do manually: in a worker's filter we need to change skill id to the one we've created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ae474e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] toloka.client: A new pool with ID \"38456278\" has been created. Link to open in web interface: https://toloka.yandex.com/requester/project/138319/pool/38456278\n"
     ]
    }
   ],
   "source": [
    "main_pool.filter.and_[1].or_[0].key=skill.id\n",
    "main_pool.quality_control.configs[3].rules[0].action.parameters.skill_id = skill.id\n",
    "main_pool=toloka_client.create_pool(main_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c529807",
   "metadata": {},
   "source": [
    "Now we will get random sample from FEIDEGGER dataset and create tasks with algorith described in Gomes et al. (2011). Number of images in sample `N` may be set manually. In the paper we used N=2000 images, but in demonstration one may decrease this amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc121c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # number of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a67fd38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_csv('configs/dress/project/dataset.csv')['image_url'].values.tolist()\n",
    "urls_sample = sample(urls, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c66774a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 8 \n",
      "N: 100 \n",
      "V: 14\n",
      "init_items: 1 \n",
      "unique_hits: 175\n",
      "\n",
      "TOTAL PRICE: 7.875\n"
     ]
    }
   ],
   "source": [
    "M = 8 # number of objects in each HIT\n",
    "V = int(log(N, 2)*log(N, M)) # expecting number of HITs to which a data item belongs\n",
    "R = 3 # overlap\n",
    "print('M:', M, '\\nN:', N, '\\nV:', V)\n",
    "\n",
    "initial_items = max(int(M/V), 1)\n",
    "unique_hits = int(N*V/M)\n",
    "print('init_items:', initial_items, '\\nunique_hits:', unique_hits)\n",
    "print('\\nTOTAL PRICE:', unique_hits * R * 0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2953fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_samples(images: Set[str], unique_hits: int, objects_number: int, \n",
    "           objects_per_hit_number: int, initial_items: int) -> List[toloka.Task]:\n",
    "    hits = np.array_split(list(images), min(objects_number, unique_hits))\n",
    "    for i, hit in enumerate(hits):\n",
    "        not_in_hit = images - set(hit)\n",
    "        hit_sample = sample(not_in_hit, objects_per_hit_number - initial_items)\n",
    "        hits[i] = np.append(hit, hit_sample)\n",
    "    return hits\n",
    "\n",
    "hits = hit_samples(set(urls_sample), unique_hits, N, M, initial_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "585de7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_suites = [\n",
    "    toloka.task_suite.TaskSuite(\n",
    "        pool_id=main_pool.id,\n",
    "        tasks=[\n",
    "            toloka.task.Task(input_values={'images': hit.tolist()})\n",
    "        ]\n",
    "    )\n",
    "    for hit in hits\n",
    "]\n",
    "\n",
    "task_suites = toloka_client.create_task_suites(task_suites, allow_defaults=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebba02b",
   "metadata": {},
   "source": [
    "# Receiving responses\n",
    "\n",
    "So, we have finished all preparations, now is the time to start labelling.\n",
    "\n",
    "We are going to open all our pools: training, exam and main pool. All pools will stay open untill the main pool is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e1924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] toloka.client: Experimental method\n",
      "[INFO] root: Pool 38456278 - 0%\n",
      "[WARNING] toloka.client: Experimental method\n",
      "[INFO] root: Pool 38456278 - 0%\n",
      "[WARNING] toloka.client: Experimental method\n",
      "[INFO] root: Pool 38456278 - 0%\n",
      "[WARNING] toloka.client: Experimental method\n",
      "[INFO] root: Pool 38456278 - 0%\n"
     ]
    }
   ],
   "source": [
    "period: timedelta = timedelta(seconds=60)\n",
    "\n",
    "training = toloka_client.open_training(training.id)\n",
    "exam_pool = toloka_client.open_pool(exam_pool.id)\n",
    "main_pool = toloka_client.open_pool(main_pool.id)\n",
    "\n",
    "while main_pool.is_open():\n",
    "    exam_check(toloka_client, exam_pool, skill)\n",
    "    op = toloka_client.get_analytics([toloka.analytics_request.CompletionPercentagePoolAnalytics(subject_id=main_pool.id)])\n",
    "    percentage = toloka_client.wait_operation(op).details['value'][0]['result']['value']\n",
    "    logging.info(f'Pool {main_pool.id} - {percentage}%')\n",
    "\n",
    "    sleep(period.total_seconds())\n",
    "    main_pool = toloka_client.get_pool(main_pool.id)\n",
    "\n",
    "exam_check(toloka_client, exam_pool, skill)\n",
    "training = toloka_client.close_training(training.id)\n",
    "exam_pool = toloka_client.close_pool(exam_pool.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265b41c",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "After getting our data labelled, we need to aggregate our data using our implementation of algorithm described in [Crowdclustering by Ryan Gomes et. al.](http://vision.caltech.edu/~gomes/papers/crowd_clust_final.pdf) and [Incremental Learning of Nonparametric Bayesian Mixture Models by Ryan Gomes et. al.](http://www.vision.caltech.edu/gomes/papers/gomes_cvpr_08.pdf). Our implementation is based on [original Matlab implementation](http://www.vision.caltech.edu/gomes/software.html).\n",
    "\n",
    "It will take quite a while for aggregation process to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2449ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments_raw = toloka_client.get_assignments_df(pool_id=main_pool.id)[\n",
    "        ['INPUT:images', 'OUTPUT:result', 'GOLDEN:result', 'ASSIGNMENT:link', 'ASSIGNMENT:assignment_id',\n",
    "         'ASSIGNMENT:worker_id', 'ASSIGNMENT:status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cluster_dict = {}\n",
    "while len(cluster_dict) != 4:\n",
    "    prior = Prior(1, 5, 10, 1)\n",
    "    cluster_dict, id_to_img, clustering_result = clustering_aggregation(assignments_raw, 'INPUT:images', prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a49081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n clusters:', len(cluster_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ec886",
   "metadata": {},
   "source": [
    "Finally, let's output results of clustering by crowd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b56754",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = StandardScaler().fit_transform(pd.DataFrame(clustering_result.data.singlets.transpose()))\n",
    "x = pd.DataFrame(x)\n",
    "img_to_cluster = dict()\n",
    "for cluster, img_list in cluster_dict.items():\n",
    "    for img in img_list:\n",
    "        img_to_cluster[img] = cluster\n",
    "pca = PCA()\n",
    "x_pca = pca.fit_transform(x)\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "x_pca.head()\n",
    "x_pca['target'] = [img_to_cluster[x] for x in id_to_img.values()]\n",
    "x_pca.columns = ['PC1','PC2','PC3','PC4','target']\n",
    "x_pca.head()\n",
    "targets = list(cluster_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4829d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(150, 105))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "colors = ['c', 'r', 'y', 'g', 'b', 'k', 'm', ][:len(set(targets))]\n",
    "for target, color in zip(targets, colors):\n",
    "    indicesToKeep = x_pca['target'] == target\n",
    "    ax.scatter(x_pca.loc[indicesToKeep, 'PC1'],\n",
    "               x_pca.loc[indicesToKeep, 'PC2'],\n",
    "               c = color,\n",
    "               s = 5000)\n",
    "    sample_row = x_pca.sample(1)\n",
    "    sample_idx = sample_row.index[0]\n",
    "    img_url = id_to_img[sample_idx]\n",
    "    img = Image.open(urlopen(img_url))\n",
    "    imagebox = OffsetImage(img, zoom=1)\n",
    "    x = sum(x_pca.loc[indicesToKeep, 'PC1']) / len(x_pca.loc[indicesToKeep, 'PC1'])\n",
    "    y = sum(x_pca.loc[indicesToKeep, 'PC2']) / len(x_pca.loc[indicesToKeep, 'PC2'])\n",
    "    ab = AnnotationBbox(imagebox, (x, y))\n",
    "    ax.add_artist(ab)\n",
    "ax.grid()\n",
    "fig.savefig('clustering_visualization.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879fdc5c",
   "metadata": {},
   "source": [
    "# Quality evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ed03e",
   "metadata": {},
   "source": [
    "After getting results, we can evaluate quality of clusters. To do this we use appoach called <i>Intruders</i> described in https://proceedings.neurips.cc/paper/2009/hash/f92586a25bb3145facd64ab20fd554ff-Abstract.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d050e31",
   "metadata": {},
   "source": [
    "The idea is to make HITs with one image from one cluster and others from another cluster. We ask worker to find this extra image and if this object was found, then objects from these two clusters are quite different from each other. The proportion of correct answers will be \"quality\" in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a97ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_intruder_hits(cluster_dict, N_HITS=100, images_on_page=8) -> List[List[str]]:\n",
    "    hits_list = list()\n",
    "    for _ in range(N_HITS):\n",
    "        cluster, intrusor_cluster = sample(cluster_dict.keys(), 2)\n",
    "        images = cluster_dict[cluster]\n",
    "        intrusor_images = cluster_dict[intrusor_cluster]\n",
    "        while len(images) < images_on_page - 1:\n",
    "            cluster, intrusor_cluster = sample(cluster_dict.keys(), 2)\n",
    "            images = cluster_dict[cluster]\n",
    "            intrusor_images = cluster_dict[intrusor_cluster]\n",
    "        representatives = sample(images, images_on_page - 1)\n",
    "        intrusor = sample(intrusor_images, 1)\n",
    "        HIT = representatives + intrusor\n",
    "        shuffle(HIT)\n",
    "        hits_list.append(HIT)\n",
    "    return hits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce169f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HITS = 100\n",
    "images_on_page = 8\n",
    "intruder_hits = make_intruder_hits(cluster_dict, N_HITS, images_on_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d7e714",
   "metadata": {},
   "source": [
    "## Create main project and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2119a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "intruders_project = create_project_from_file('configs/dress/quality_evaluation/project/project.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a95e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "intruders_training = create_training_from_file(\n",
    "    'configs/dress/quality_evaluation/project/training.json', intruders_project.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3921b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = create_tasks_from_config(\n",
    "    'configs/dress/quality_evaluation/training_tasks/training_tasks.json', intruders_training.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "intruders_pool = create_pool_from_file(\n",
    "    'configs/dress/quality_evaluation/project/pool.json', intruders_project.id, intruders_training.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_suites = [\n",
    "    toloka.task_suite.TaskSuite(\n",
    "        pool_id=intruders_pool.id,\n",
    "        tasks=[\n",
    "            toloka.task.Task(input_values={'images': hit})\n",
    "        ]\n",
    "    )\n",
    "    for hit in intruder_hits\n",
    "]\n",
    "\n",
    "task_suites = toloka_client.create_task_suites(task_suites, allow_defaults=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d56b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "period: timedelta = timedelta(seconds=60)\n",
    "\n",
    "intruders_training = toloka_client.open_training(intruders_training.id)\n",
    "intruders_pool = toloka_client.open_pool(intruders_pool.id)\n",
    "\n",
    "while intruders_pool.is_open():\n",
    "    op = toloka_client.get_analytics(\n",
    "        [toloka.analytics_request.CompletionPercentagePoolAnalytics(subject_id=intruders_pool.id)]\n",
    "    )\n",
    "    percentage = toloka_client.wait_operation(op).details['value'][0]['result']['value']\n",
    "    logging.info(f'Pool {intruders_pool.id} - {percentage}%')\n",
    "\n",
    "    sleep(period.total_seconds())\n",
    "    intruders_pool = toloka_client.get_pool(intruders_pool.id)\n",
    "\n",
    "intruders_training = toloka_client.close_training(intruders_training.id)\n",
    "intruders_pool = toloka_client.close_pool(intruders_pool.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec94e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments_raw = toloka_client.get_assignments_df(pool_id=intruders_pool.id)[\n",
    "        ['INPUT:images', 'OUTPUT:answer', 'GOLDEN:answer', 'ASSIGNMENT:link', 'ASSIGNMENT:assignment_id',\n",
    "         'ASSIGNMENT:worker_id', 'ASSIGNMENT:status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_quality(assignments_raw, cluster_dict, intruder_hits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
